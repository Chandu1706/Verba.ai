
ğŸ“± Verba.ai â€“ Audio Transcription iOS App

Verba.ai is a production-ready iOS audio recording and transcription application. It supports real-time waveform visualization, background-safe recording, intelligent segmentation, cloud + offline transcription, and large-scale session management using SwiftData.


âœ… Features

ğŸ™ High-quality audio recording  using `AVAudioEngine`
ğŸ§  Automated 30-second segmentation and transcription (AssemblyAI + Apple fallback)
ğŸ”Š Real-time waveform animation
ğŸ“‚ Session browser with date grouping, inline transcription previews, and export
ğŸ›  Customizable audio quality and dark/light mode toggle
 ğŸ” Offline fallback using Appleâ€™s speech recognition
ğŸ” SwiftData-backed local persistence
âš™ï¸ Full support for route changes, interruptions, and background recording


ğŸ“¦ Requirements

â€¢	Xcode 15+
â€¢	iOS 17+
â€¢	Swift 5.9+

ğŸ›  Setup Instructions

1.	Clone the repository
First you need to clone this repository into your desired folder,

   ```
   git clone https://github.com/your-username/verba-ai.git
   cd verba-ai
   ```

2. Open the Xcode project

   ```bash
   open Verba.xcodeproj
   ```

5. Build and run on a real device 

 You can connect to a real ios device and run it to see the execution or you can even use a simulator.
(Note : Recording and speech recognition donâ€™t work on the simulator.)


ğŸ§ª Testing

This project includes a full suite of unit, integration, and performance tests.

 âœ… Types of Tests Included

1. Unit Tests 
   Validate core business logic and SwiftData models.

2. Integration Tests
   Ensure end-to-end functionality with AssemblyAI transcription.

3. Error & Interruption Handling  
   Simulate poor network, audio route changes, app backgrounding.

4. Performance Testing
   Simulate large datasets (1,000+ sessions, 10,000+ segments).

 â–¶ï¸ How to Run Tests in Xcode

1. Open the project in Xcode:

   ```bash
   open Verba.xcodeproj
  

2. Select a real device  or simulator (some tests may require device).

3. Open the Test Navigator  
   Press `âŒ˜ + 6` or go to `View > Navigators > Show Test Navigator`.

4. Run individual tests  
   Click the play icon next to any test case or test method.

5. Run all tests 
   Press `âŒ˜ + U` or go to `Product > Test`.

 ğŸ§ª Test Targets

 `VerbaTests`: Unit tests for SwiftData and audio logic
 `VerbaUITests`: UI-level testing for flows and navigation
`VerbaPerformanceTests`: Optional stress tests for large data loads

 ğŸ’¡ Tip: Use "Profile" (âŒ˜ + I) to inspect memory, disk, and energy use under real workloads.






âš™ï¸ Configuration

Use the Settings screen in the app to:
â€¢	Toggle audio quality (high/normal)
â€¢	Enable/disable fallback to local transcription
â€¢	Manually switch between light/dark/system themes



ğŸ“ Folder Structure


â”œâ”€â”€ Controllers/
â”‚   â”œâ”€â”€ AudioManager.swift
â”‚   â”œâ”€â”€ TranscriptionService.swift
â”‚
â”œâ”€â”€ Models/
â”‚   â”œâ”€â”€ RecordingSession.swift
â”‚   â”œâ”€â”€ RecordingSegment.swift
â”‚
â”œâ”€â”€ Views/
â”‚   â”œâ”€â”€ ContentView.swift
â”‚   â”œâ”€â”€ SessionListView.swift
â”‚   â”œâ”€â”€ SettingsView.swift
â”‚   â”œâ”€â”€ AboutView.swift
â”‚   â””â”€â”€ WaveformBar.swift



ğŸ“¤ Exporting Sessions

You can long-press a session to select it, then tap Export & Share to save the full CSV transcription (session + segments).


  Bonus Features Implemented

â€¢	Noise reduction + reverb (custom audio processing)
â€¢	FTS-based advanced search to search by transcriptions as well
â€¢	Offline fallback transcription
â€¢	Export to `.csv`
â€¢	Dark/light mode override
â€¢	Settings screen
â€¢	Swipe left on session to delete it
  Widget support for the app


## FAQ

Can I test without a real API key?
  Yes, but transcription will fail and fallback to Appleâ€™s speech recognition after 5 retries.

Can I use this with Whisper or another model? 
  Yes, just swap the TranscriptionService logic.


## Documentation
 ğŸ“„ [View Full Documentation (PDF)](verba/Docs/Verba.pdf)

 
## Contributors

 Chandu Korubilli â€“ Developer & Architect
 




